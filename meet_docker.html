<!DOCTYPE html>
<html>
  <head>
    <title>Meet Docker!</title>
    <link rel="stylesheet" href="style.css"> 
  </head>
  <body>
    <div class="main-talk">
      <div class="section1">
        <p class="content-head-docker">Meet the Doc(ker)</p>
        <img class="img-docker" src="static/docker.svg">
      </div>
      <div class = "section2">
                <!--<div class="content-head-meet-sinjini">
         Meet Sinjini<span class="short-content"> (she/her) pronounced as [SHIN-jee-nee]</span>
</div>-->
       <div class="content-sub"> 
          If you are an aspiring <span class="highlight-purple">Developer</span> or <span class="highlight-purple">SRE</span>, you will eventually come across the term <span class="highlight-purple">DOCKER</span>! Docker is essential these days. The main goal of this write-up is to explain everything I have learned about Docker, from basics to intermediate to advanced. It’s a win-win scenario: I will be explaining what I’ve learned (which helps reinforce my understanding – <span class="highlight-purple">Feynman Technique</span>), and you will have the opportunity to learn what you might have missed or want to revise. <b>Today we will focus on <span class="highlight-purple">WHYs for using Docker</span> as a containerisation tool.</b> Let's get started!       
        </div>
        <br>
        <div class="content-head">
          <span class="highlight-purple">Quick links</span>
          <ul class="content-sub">
            <li><a href="#scenario 1">Environmental inconsistency and Isolation issues </a></li>
            <li><a href="#scenario 2">Resource Intensive</a></li>
            <li><a href="#scenario 3">Scaling and other DevOps practices</a></li>
            <li><a href="#how_docker_helps">How docker helps</a></li>
          </ul>
        </div>
        <br>
        <div class="content-head">
          What is Docker?
        </div>
        <div class="content-sub">
          Docker is a tool for containerization. Is that all? Yes, that’s it. Similar to Docker, there are many other containerization tools such as Podman, CRI-O, Containerd, and rkt (Rocket). So, our focus now is to answer the question: What is <span class="highlight-purple">containerization?</span>
        </div>
        <br>
        <div class="content-head">
          What is Containerization?
        </div>
        <div class="content-sub">
          Containerization is the process of running different processes in isolation with their own dependencies on a single local system.
It may seem simple, but let’s dive deeper into the problems it solves.
        </div>
        <br>
        <div class="content-sub highlight">
          <span class="highlight-purple" id="scenario 1"><b>Scenario 1</b></span>
        </div>
        <br>
        <div class="content-sub">
          You have two Python applications that you want to run on your local system. The Python version on your system is 3.10, but one application requires Python 3.7 and the other requires Python 3.8.
You think, "Let’s give it a try. What if it runs anyway?" You attempt to run the first application, but it throws an error: "RuntimeError: This application requires Python 3.7 or above. Current version: 3.10."
          Sad<span class="highlight-purple"> :(</span><br><br>
You decide to downgrade your Python version to 3.7. Now it works for the first application, but what about the second application? Upgrading to Python 3.8? While this might work once, you can't run both applications simultaneously on your system.
          <br> <br>Wait! You still have a comeback left, you might consider using Python virtual environments. <br><br>While virtual environments like venv or pyenv can help manage different Python versions and prevent package conflicts, they can't solve problems related to OS differences. Sometimes code that runs fine on your system fails on a colleague’s system due to differences in OS and system libraries. This issue is not unique to Python; other languages like C/C++, Go, Rust, and Node.js face similar challenges. Although these languages have their own methods for managing packages and versions, the problem of OS and system library differences remains.
        </div>
        <br>
        <div class="content-sub">
          <b>The Problems</b>
        </div>
        <div class="content-sub">
          The issues we just saw are:
          <br>
          <ul>
            <li><b><span class="highlight-purple">Environmental Inconsistency:</b></span> Applications behave differently in production, development, and testing environments due to differences in system configuration, libraries, and OS.</li>
            <li><b><span class="highlight-purple">Lack of Isolation:</b></span> Applications with different versions of dependencies cannot be run simultaneously on a single system.</li>
          </ul>
        </div>
        <br>
        <div class="content-sub highlight-purple highlight" id="scenario 2">
          <b>Scenario 2</b>
        </div>
        <div class="content-sub">
          <br>
          On any given day, if you choose to use <span class="highlight-purple">VMs (virtual machines)</span> to run applications with different dependencies to achieve isolation on a single local system, think again!<br><br>
          It's true that VMs can help prevent the problem we face regarding system dependencies and differences in OSs. However, it’s a very resource-intensive solution.<br><br>
VMs use OS images (e.g., .iso files), which include a bootloader, kernel, filesystems, packages, etc., to load an operating system inside your local system that already has its own OS running. Essentially, VMs give us the ability to run multiple operating systems inside a single local system, but using VMs solely to run applications is not an efficient solution. Just imagine: your CPU and RAM are now being utilized by the kernel and system programs of both your local system and the VMs simultaneously. Therefore, running multiple VMs just to support applications is resource-intensive. This can significantly degrade the performance of both your system and the applications, placing a heavy load on your resources.
        </div>
        <br>
        <div class="content-sub">
          <b>The Problems</b>
        </div>
        <div class="content-sub">
          <ul>
            <li><b><span class="highlight-purple">Resource Intensive</span></b>: Even though VMs can provide isolation by running different OSs in a single system, it will be very resource intensive.</li>
          </ul>
        </div>
        <br>
        <div class="content-sub highlight-purple highlight" id="scenario 3">
            <b>Scenario 3</b>
        </div> 
        <br>
         <div class="content-sub">
          Say your application has been running successfully on your server, but now it’s gaining popularity. With increasing users, you start facing performance issues. So, what’s the solution? Do you simply throw more money at the problem by adding more servers? While that might seem like a quick fix, it also involves provisioning new servers, installing all necessary dependencies, and deploying the application multiple times. This process can become time-consuming, expensive, and inefficient, especially as user demand continues to grow.
          <br>
          <br>
          Apart from scaling, if you are using traditional DevOps practices to integrate your code, building, testing and deploying them which lacks automation will cause higher risk of human error, slower feedback loops, less frequent releases, etc.
         </div>
        <br>
        <div class="content-sub">
          <b>The Problems</b>
        </div>
         <div class="content-sub">
           <ul>
             <li><b><span class="highlight-purple">Scaling</span></b>: Even though VMs can provide isolation by running different OSs in a single system, it will be very resource intensive.</li>
            <li><b><span class="highlight-purple">DevOps practices</span></b>: Manual Techniques prevent productivity.</li>
           </ul>
         </div>
        <br>
        <div class="content-head highlight-purple" id="how_docker_helps">
          <b> How Docker helps???</b>
        </div>
        <br>
        <div class="content-sub">
          Now that we have discussed some of the problems in detail, let's look at how Docker addresses them.
          <br>
          Docker has a concept of <span class="highlight-purple">images</span>,  which are like blueprints or plans for real-world projects, containing everything needed to make the project a reality. Docker images specifies the requirements with the exact versions of the dependencies making the project error free.
          <br><br>
          Let’s say you've developed a Python project on your Ubuntu server, but your friend has a Windows machine with a different version of Python. No worries—just share the Docker image you’ve built. It includes dependencies like Ubuntu, Python, and the necessary commands to install the required packages. All your friend has to do is run the image and boom! The Python application is now running on your friend's machine, without the need for a separate local system or VM for Ubuntu, or installing a different Python version. This provides a solution for <span class="highlight-purple">environmental inconsistency</span>. Due to portable in nature we can use this image build and run the containers in multiple systems.
          <br><br>
          Docker images can be pulled from docker registery (the site is called Docker hub) or can be manually created using Dockerfile.
          <pre><code class="highlight-purple content-sub">
                FROM ubuntu:latest
                WORFKDIR /app 
                RUN apt-get update && \
                    apt-get install -y python3 python3-pip &&\
                COPY requirements.txt .
                RUN pip3 install --no-cache-dir -r requirements.txt 
                COPY . .
                CMD ["python3", "app.py"]
              </code></pre>
          <div class="content-sub">
            Above is an example of Dockerfile to build an image that will run a python application by installing all the required packages in a ubuntu base image, we will dive deep into Dockerfile and Docker images in our upcomming talks!
            <br><br>
            Once you have saved the file with the name "Dockerfile" run the command
            <span class="highlight-purple">docker build -t python:ubuntu .</span>
            The above command will create an image out of it, generating an image id. In case you have named your Dockerfile something else, you can use the below command -
            <br><span class="highlight-purple">docker build -f <i>custom_name_of_dockerfile</i> -t <i>name_of_your_image</i> .</span>
            <br><br>
             
            Once the image is built, it's time to see our application running seamlessly, and for that, we need to create a running container. 
            <span class="highlight-purple"><b>What is a container?</b></span> Like a container that stores stuff? 
            Yes, but this container holds your application and its dependencies, and it can also run the application. It’s essentially a live container! 
            Let's recall what else a container can do—it separates things out and provides 
            <span class="highlight-purple"><b>isolation</b></span>. Docker containers can run different applications with different dependencies and versions in isolation, preventing any kind of conflicts on a single system. Infact if these containers are supposed to run same applications with same dependencies just use that same image to create multiple similar conatainers, cool I know.
            <br><br>
            Now that we have an idea of how Docker isolates processes, let’s dig a little deeper to understand why it’s not <span class="highlight-purple">resource-intensive</span>. You might wonder, considering Docker images use operating systems like Ubuntu (as seen in our previous example of Docker images and Dockerfiles), wouldn’t that generate a significant load on our system’s resources?
            <br><br>
            Well, here’s the key: Docker doesn’t install a separate OS kernel. Instead, it shares the kernel from your local system for resource management. The only components that get installed are the minimal user-space elements, which include the necessary system libraries, commands, utilities, configuration files, and some background services like daemons. These user-space components run outside the kernel, which significantly reduces the resource footprint compared to virtual machines.
            <br><br>
          To build and run a container, use the command: <span class="highlight-purple">docker run -d -p <i>hostport:containerport</i> --name <i>name_of_container</i> <i>image_name</i></span>, where -d runs the container in detached mode (in the background), -p specifies port mapping (which port of the host will map to which port of the container), and the --name flag assigns a name to the container. You can skip the --name flag, and Docker will assign a unique, random name for the container.
            <br><br>
            The rest two issues which we are yet to find out if Docker is able to solve are Scaling, DevOps practices. Let's go.      <br><br>
            Fast and efficient <span class="highlight-purple">Scaling</span> in docker is possible with Docker compose, a tool to manage mutiple containers which benifits if anyone seeking to implement multi-tier application(which involves backend services, databases,etc) using docker or wants to scale its applications to manage high traffic.
            <br><br>
            In <span class="highlight-purple">DevOps</span>, along with scaling and environmental inconsistency, managing <span class="highlight-purple">CI/CD</span> pipeline was a challenge, in which two of them we have already discussed how docker solves them. Docker allows you to streamline your CI/CD process. Every time a developer pushes new code, the CI pipeline automatically builds a new Docker image of the application, runs tests inside the container, and pushes the tested image to a container registry. From there, CD tools can quickly deploy the container to any environment, whether on cloud platforms like AWS, GCP, or Kubernetes clusters. Other tools like Jenkins, Ansible, Terraform further reduces manual work on CI/CD pipelines making the process more <span class="highlight-purple">productive</span>.

            <br><br>
            Thus, containerization is indeed important, and due to its user-friendly interface and strong community support, Docker has proven to be a highly useful tool these days. Docker indeed has many limitations for which other containerisation tools can be a good replacement but again, that depends upon the goal and preferences.
            <br><br>
            A small <span class="highlight">suggestion</span>, if you want to try docker, Docker's documentations has done a very good job. Look for the sections <span class="highlight-purple">"Guide"</span> which specifically for concepts and introduction with docker utilities, <span class="highlight-purple">"Reference"</span> for CLI utilities and commands with proper explanation and <span class="highlight-purple">"Manuals"</span> for deep dive. <span class="highlight-purple">Happy exploring!</span>
          </div>
          <br>
          <div class="author-section author-section-border">
            <div class="footer-img-section">
              <img class="footer-img" src="static/images/profile2.png">
            </div>
            <div class="author-intro">
              <b>About Author:</b><br><b>Sinjini Banerjee</b><br><b>Cloud Engineer Intern at Nervescape LLP</b>
            </div>
          </div>
      </div>
        <div class="center"><br><br><br> © Copyright 2024. All right Reserved.</div>
        <div class="center">
          <p id="lastUpdated"></p>
        </div>
        
      </div>
    </div>
     <script>
        const lastModified = new Date(document.lastModified);
        const formattedDate = lastModified.toLocaleDateString('en-US', {
            year: 'numeric',
            month: 'long',
            day: 'numeric'
        });

        document.getElementById('lastUpdated').textContent = `Last updated on: ${formattedDate}`;
    </script>

  </body>
</html>
